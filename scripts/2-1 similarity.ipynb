{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a837e3d",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31449f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import gensim\n",
    "\n",
    "# 提取指定门类进行 TF-IDF 矩阵构建：\n",
    "for N in [8,10,5,4,12,9,7,2,13,3,1]:\n",
    "    result = []\n",
    "    for i in range(cut_word_list.shape[0]):\n",
    "        if cut_word_list.iloc[i]['Tag'] == int(N):\n",
    "            result.append(cut_word_list.iloc[i]['分词结果'])\n",
    "    result = pd.DataFrame(result,columns=['分词结果'])\n",
    "    \n",
    "     # 计算 TF-IDF 值\n",
    "    tfvectorizer=CountVectorizer(lowercase=False) \n",
    "    count_vector=tfvectorizer.fit_transform(result['分词结果']) # Tf 矩阵\n",
    "    transformer = TfidfTransformer() # 转换 Tf 矩阵\n",
    "    tfidf = transformer.fit_transform(count_vector) # 将 TF 转换成 Tf-Idf\n",
    "    tfvectorizer_feature_names = tfvectorizer.get_feature_names()\n",
    "    tfvectorizer_vocabulary = tfvectorizer.vocabulary_\n",
    "    tfidf_result = tfidf.toarray()\n",
    "    tfidf.toarray().sum(axis=0)\n",
    "    data = {'word': tfvectorizer_feature_names,\n",
    "        'tfidf': tfidf.toarray().sum(axis=0).tolist()}\n",
    "    key_word = pd.DataFrame(data)\n",
    "    key_word_sort=key_word.sort_values(by=\"tfidf\" , ascending=False) \n",
    "    final_key=key_word_sort.head(100)\n",
    "    \n",
    "    \n",
    "    for j in range(1,5):\n",
    "        simi_dimension=[]\n",
    "        standard = pd.read_excel('standard'+str(j) +'10.xlsx')\n",
    "        standard_word=standard[\"word\"]\n",
    "        standard_len=len(standard_word)\n",
    "        comment_word=final_key[\"word\"]\n",
    "        commet_len=len(comment_word)\n",
    "        all_word=[]\n",
    "        for s in standard_word:\n",
    "            all_word.append(s)\n",
    "        for m in comment_word:\n",
    "            all_word.append(m)\n",
    "   \n",
    "        model =gensim.models.Word2Vec([all_word],min_count=0,window=5)\n",
    "        for a in range(commet_len):\n",
    "            all_similarity=[]\n",
    "            for b in range(standard_len):\n",
    "                similarity=model.wv.similarity(all_word[standard_len+a],all_word[b])\n",
    "                all_similarity.append(similarity)\n",
    "    \n",
    "            simi_dimension.append(max(all_similarity))\n",
    "        final_key[\"similarity{}\".format(j)]=simi_dimension  \n",
    "     \n",
    "    #获取每个类别各个维度的词典\n",
    "    #final_key.to_excel('dictionary'+str(N) +'.xlsx' , index=None)\n",
    "    dimesion1=[]\n",
    "    dimesion2=[]\n",
    "    dimesion3=[]\n",
    "    dimesion4=[]\n",
    "    final_simi=final_key[[\"similarity1\",\"similarity2\",\"similarity3\",\"similarity4\",]]\n",
    "    index_simi=final_simi.idxmax(axis=1)\n",
    "    for i in range(len(index_simi)):\n",
    "        if index_simi.iloc[i]==\"similarity1\":\n",
    "            dimesion1.append(final_key.iloc[i,0])\n",
    "        elif index_simi.iloc[i]==\"similarity2\":\n",
    "            dimesion2.append(final_key.iloc[i,0])\n",
    "        elif index_simi.iloc[i]==\"similarity3\":\n",
    "            dimesion3.append(final_key.iloc[i,0])\n",
    "        else:\n",
    "            dimesion4.append(final_key.iloc[i,0])\n",
    "            \n",
    "    df_dime1 = pd.DataFrame(dimesion1, columns=['选题与综述'])\n",
    "    df_dime2 = pd.DataFrame(dimesion2, columns=['创新与论文价值'])\n",
    "    df_dime3 = pd.DataFrame(dimesion3, columns=['科研能力与基础知识'])\n",
    "    df_dime4 = pd.DataFrame(dimesion4, columns=['论文规范性'])\n",
    "    dim_word = pd.concat([df_dime1,df_dime2,df_dime3,df_dime4],axis=1)\n",
    "    dim_word.to_excel('final词典'+str(N) +'.xlsx' , index=None)\n",
    "    #tfidf_result = pd.DataFrame(tfidf_result,columns=tfvectorizer_feature_names)\n",
    "    #tfidf_result = pd.DataFrame(tfidf_result,columns=tfvectorizer_feature_names)\n",
    "    #print(N)\n",
    "    #paths = 'subject'+str(N) +'tf_idf.xlsx' \n",
    "    #tfidf_result.to_excel(paths,encoding = 'utf-8-sig')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
