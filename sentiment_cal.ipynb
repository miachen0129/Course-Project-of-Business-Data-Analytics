{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5384101-6a39-46ef-b008-24cf227f8c3d",
   "metadata": {},
   "source": [
    "# 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "111651c6-d1ab-4543-99e7-1dad5f104298",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel(\"raw.xlsx\")\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "623c2f71-5ee5-481e-8246-71f7e3275c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预处理\n",
    "def preprocessing():\n",
    "    for i in range(1,4):\n",
    "        # X1,X2,X3分别讨论\n",
    "        total_col = 'X%s'%i # 生成总分列名\n",
    "        cols = ['X%s%s'%(i,j) for j in range(1,5)] # 生成小分列名\n",
    "        for j in range(4):\n",
    "            # 找出满足Xij>25的数据 of 空值\n",
    "            dfd = df[df[cols[j]] > 25 | df[cols[j]].isnull()]\n",
    "            if dfd.empty:\n",
    "                continue\n",
    "            # 按照总分反推小分\n",
    "            dfd.loc[:, cols[j]] = dfd.loc[:,total_col] - dfd.loc[:,cols[(j+1)%4]] - dfd.loc[:,cols[(j+2)%4]] - dfd.loc[:,cols[(j+3)%4]]\n",
    "            # 更新修改的数据行\n",
    "            df.update(dfd)\n",
    "        # 处理总分与小分不一致的情况\n",
    "        df.loc[:,total_col] = dfd.loc[:,cols[0]:cols[-1]].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69bc64aa-e57c-4b61-a412-b11db40fcea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算总分\n",
    "def totalCal():\n",
    "    df['Avg1'] = df[['X11','X21','X31']].mean(axis=1)\n",
    "    df['Avg2'] = df[['X12','X22','X32']].mean(axis=1)\n",
    "    df['Avg3'] = df[['X13','X23','X33']].mean(axis=1)\n",
    "    df['Avg4'] = df[['X14','X24','X34']].mean(axis=1)\n",
    "    df['Avg'] = df[['X1','X2','X3']].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db4b1e37-557a-4fdd-9389-44c5592ba418",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z7/_85qg8c535vfyc7_26cmtdwm0000gn/T/ipykernel_6018/828555964.py:13: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  dfd.loc[:, cols[j]] = dfd.loc[:,total_col] - dfd.loc[:,cols[(j+1)%4]] - dfd.loc[:,cols[(j+2)%4]] - dfd.loc[:,cols[(j+3)%4]]\n",
      "/var/folders/z7/_85qg8c535vfyc7_26cmtdwm0000gn/T/ipykernel_6018/828555964.py:17: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df.loc[:,total_col] = dfd.loc[:,cols[0]:cols[-1]].sum(axis=1)\n",
      "/var/folders/z7/_85qg8c535vfyc7_26cmtdwm0000gn/T/ipykernel_6018/828555964.py:17: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df.loc[:,total_col] = dfd.loc[:,cols[0]:cols[-1]].sum(axis=1)\n"
     ]
    }
   ],
   "source": [
    "preprocessing()\n",
    "totalCal()\n",
    "\n",
    "df.to_excel('Final.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47f0cd8-a606-4761-ac36-9beda04399cd",
   "metadata": {},
   "source": [
    "# 评论数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad40d14a-4b22-4aa1-89ea-56db6a65735b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from jieba import lcut\n",
    "from jieba import cut\n",
    "import jieba.posseg\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def31ee6-0989-464c-a078-271de08581eb",
   "metadata": {},
   "source": [
    "## 通用函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b985a836-927d-495f-add1-5af9366df5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 停用词\n",
    "def loadStopwords():\n",
    "    stopwords1 = pd.read_csv('/Users/antonchekhov/Desktop/BA_nlp/stopwords/中文停用词库.txt', encoding=\"gbk\",names=[\"stopword\"])[\"stopword\"].tolist()\n",
    "    stopwords2 = pd.read_csv('/Users/antonchekhov/Desktop/BA_nlp/stopwords/百度停用词列表.txt', encoding=\"gbk\",names=[\"stopword\"])[\"stopword\"].tolist()\n",
    "    stopwords3 = pd.read_csv('/Users/antonchekhov/Desktop/BA_nlp/stopwords/四川大学机器智能实验室停用词库.txt',encoding=\"gbk\",names=[\"stopword\"])[\"stopword\"].tolist()\n",
    "    stopwords = stopwords3 + stopwords2 + stopwords1\n",
    "    stopwords.extend(list(';: .)(（）-——①②③④⑤⑥⑦⑧⑨'))\n",
    "    return stopwords\n",
    "stopwords = loadStopwords()\n",
    "\n",
    "\n",
    "# 分词\n",
    "def tokenize(sent, func):\n",
    "    \"\"\"\n",
    "    去停用词+分词操作\n",
    "    :param sent: 短句文本\n",
    "    :param func: 分词操作函数\n",
    "    :param stopwords: 停用词表\n",
    "    :return: 词语列表\n",
    "    \"\"\"\n",
    "    # 将句子分割成词语列表\n",
    "    words = func(sent)\n",
    "    target_ls = []\n",
    "    for word in words:\n",
    "        # 去除停用词\n",
    "        # 结果中可能包含重复词汇\n",
    "        if word not in stopwords:\n",
    "            target_ls.append(word)\n",
    "    return target_ls\n",
    "\n",
    "# 按词性分词\n",
    "def cut_words_with_pos(text):\n",
    "    seg = jieba.posseg.cut(text)\n",
    "    res = []\n",
    "    for i in seg:\n",
    "        if i.flag in [\"a\",\"ad\", \"n\", \"an\", \"vn\", \"nz\", \"nt\", \"nr\"]:\n",
    "            res.append(i.word)\n",
    "    return list(res)\n",
    "\n",
    "# 分句\n",
    "def sentCut(sents):\n",
    "    \"\"\"\n",
    "    将评论分为短句（不分词）\n",
    "    :param sents: 整段评论文字\n",
    "    :return: 短句列表\n",
    "    \"\"\"\n",
    "    if type(sents) != str:\n",
    "        return []\n",
    "    sents = sents.strip() # 去除前后空格\n",
    "    sent_ls = re.split(r'，|。|；|\\0',sents) # 按句号、分号、逗号进行划分\n",
    "    sent_ls = [s for s in sent_ls if len(s)>0] # 去除空字符\n",
    "    return sent_ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cadb6540-3dc6-4930-9d99-f16b6276fe29",
   "metadata": {},
   "source": [
    "## 数据"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa234259-1cf1-4d15-a7cd-bf162b5ad860",
   "metadata": {},
   "source": [
    "1. 用于模型（tf-idf, word2vec）训练的数据：所有评论分词+去停用词；全部整合在一起 （total_text list）\n",
    "\n",
    "2. 用于构建词典的分专业类别评论：grouped; 按专业整合再在一起 (subject_map dict)\n",
    "\n",
    "3. 用于每篇论文情感计算和打分的评论 (df[\"RList\"])\n",
    "\n",
    "4. 评价标准处理——分词，提取关键词 (target_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1bbf82b-f761-46f3-a678-32803e9fa947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取预处理后的数据\n",
    "df = pd.read_excel('Final.xlsx')\n",
    "\n",
    "# 保留评论列R1,R2,R3\n",
    "reviews_df = df[['Tag','R1','R2','R3']]\n",
    "for col in ['R1','R2','R2']:\n",
    "    reviews_df[col].map(str)\n",
    "# 删除空值，此为全部删除\n",
    "# 若指定超过两个空值就删除：df.dropna(axis = 0, thresh = 2)\n",
    "reviews_df = reviews_df.dropna()\n",
    "\n",
    "# 将评论数据处理为短句列表\n",
    "# [\" \",sent2,...]\n",
    "# 存入review_df中的R_ls中\n",
    "R_ls = []\n",
    "for row in reviews_df.itertuples():\n",
    "    # 遍历每一行\n",
    "    r_ls = [sentCut(row.R1), sentCut(row.R2), sentCut(row.R3)]\n",
    "    R_ls.append(r_ls)\n",
    "reviews_df.loc[:,\"Rlist\"] = R_ls\n",
    "\n",
    "# 按照tag分组\n",
    "grouped_reviews = reviews_df.groupby(df['Tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3b55185-7c8b-48f1-a437-c156b6117f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- 1 ----------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 17 entries, 0 to 16\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Tag     17 non-null     int64 \n",
      " 1   R1      17 non-null     object\n",
      " 2   R2      17 non-null     object\n",
      " 3   R3      17 non-null     object\n",
      " 4   Rlist   17 non-null     object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 816.0+ bytes\n",
      "None\n",
      "--------- 2 ----------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 35 entries, 17 to 65\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Tag     35 non-null     int64 \n",
      " 1   R1      35 non-null     object\n",
      " 2   R2      35 non-null     object\n",
      " 3   R3      35 non-null     object\n",
      " 4   Rlist   35 non-null     object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 1.6+ KB\n",
      "None\n",
      "--------- 3 ----------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 53 entries, 68 to 120\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Tag     53 non-null     int64 \n",
      " 1   R1      53 non-null     object\n",
      " 2   R2      53 non-null     object\n",
      " 3   R3      53 non-null     object\n",
      " 4   Rlist   53 non-null     object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 2.5+ KB\n",
      "None\n",
      "--------- 4 ----------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 72 entries, 121 to 192\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Tag     72 non-null     int64 \n",
      " 1   R1      72 non-null     object\n",
      " 2   R2      72 non-null     object\n",
      " 3   R3      72 non-null     object\n",
      " 4   Rlist   72 non-null     object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 3.4+ KB\n",
      "None\n",
      "--------- 5 ----------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 66 entries, 193 to 260\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Tag     66 non-null     int64 \n",
      " 1   R1      66 non-null     object\n",
      " 2   R2      66 non-null     object\n",
      " 3   R3      66 non-null     object\n",
      " 4   Rlist   66 non-null     object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 3.1+ KB\n",
      "None\n",
      "--------- 7 ----------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 66 entries, 261 to 331\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Tag     66 non-null     int64 \n",
      " 1   R1      66 non-null     object\n",
      " 2   R2      66 non-null     object\n",
      " 3   R3      66 non-null     object\n",
      " 4   Rlist   66 non-null     object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 3.1+ KB\n",
      "None\n",
      "--------- 8 ----------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 423 entries, 332 to 800\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Tag     423 non-null    int64 \n",
      " 1   R1      423 non-null    object\n",
      " 2   R2      423 non-null    object\n",
      " 3   R3      423 non-null    object\n",
      " 4   Rlist   423 non-null    object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 19.8+ KB\n",
      "None\n",
      "--------- 9 ----------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 64 entries, 801 to 864\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Tag     64 non-null     int64 \n",
      " 1   R1      64 non-null     object\n",
      " 2   R2      64 non-null     object\n",
      " 3   R3      64 non-null     object\n",
      " 4   Rlist   64 non-null     object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 3.0+ KB\n",
      "None\n",
      "--------- 10 ----------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 216 entries, 865 to 1090\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Tag     216 non-null    int64 \n",
      " 1   R1      216 non-null    object\n",
      " 2   R2      216 non-null    object\n",
      " 3   R3      216 non-null    object\n",
      " 4   Rlist   216 non-null    object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 10.1+ KB\n",
      "None\n",
      "--------- 12 ----------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 96 entries, 1091 to 1213\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Tag     96 non-null     int64 \n",
      " 1   R1      96 non-null     object\n",
      " 2   R2      96 non-null     object\n",
      " 3   R3      96 non-null     object\n",
      " 4   Rlist   96 non-null     object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 4.5+ KB\n",
      "None\n",
      "--------- 13 ----------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 32 entries, 1214 to 1245\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Tag     32 non-null     int64 \n",
      " 1   R1      32 non-null     object\n",
      " 2   R2      32 non-null     object\n",
      " 3   R3      32 non-null     object\n",
      " 4   Rlist   32 non-null     object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 1.5+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "for name,group in grouped_reviews:\n",
    "    print('---------',name,'----------')\n",
    "    print(group.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "796a7adb-0c6a-457f-9dc6-02caf9ad7d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1140 entries, 0 to 1245\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Tag     1140 non-null   int64 \n",
      " 1   R1      1140 non-null   object\n",
      " 2   R2      1140 non-null   object\n",
      " 3   R3      1140 non-null   object\n",
      " 4   Rlist   1140 non-null   object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 53.4+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(reviews_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62677b79-52cc-41c4-b22c-a96cd560128d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache /var/folders/z7/_85qg8c535vfyc7_26cmtdwm0000gn/T/jieba.cache\n",
      "Loading model cost 0.332 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<wordcloud.wordcloud.WordCloud at 0x130dab9d0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "text_df = reviews_df[reviews_df['Tag']==8]\n",
    "R_ls = \"\"\n",
    "for row in text_df.itertuples():\n",
    "    # 遍历每一行\n",
    "    for col in range(2,5):\n",
    "        if type(row[col]) != float:\n",
    "            R_ls += row[col]\n",
    "    \n",
    "words = lcut(R_ls)\n",
    "words = [word for word in words if word not in stopwords]\n",
    "\n",
    "from collections import Counter\n",
    "result = Counter(words).most_common(20) #取最多的50组\n",
    "#print(result)\n",
    "\n",
    "# 4.绘制词云图\n",
    "from wordcloud import WordCloud #导入相关库\n",
    "import wordcloud\n",
    "content = ' '.join(words) #把列表转换为字符串\n",
    "font_path=\"/System/Library/fonts/PingFang.ttc\"\n",
    "wc = WordCloud(font_path = font_path,\n",
    "               color_func=wordcloud.get_single_color_func(\"black\"),\n",
    "               background_color='white',#背景颜色（这里为白色）\n",
    "                width=1000,#宽度\n",
    "                height=600,#高度\n",
    "                 ).generate(content) #绘制词云图\n",
    "wc.to_file('WordCloud_8.png') #\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0ac50fd-02e9-4fa7-9a38-115a79a3d15a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tag</th>\n",
       "      <th>R1</th>\n",
       "      <th>R2</th>\n",
       "      <th>R3</th>\n",
       "      <th>Rlist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>本论文的选题很有现实意义，论文的结构合理、内容充实、论证逻辑性较强。不足之处主要有：文献综述...</td>\n",
       "      <td>论文选题具有较强的现实意义，论文结构合理，论证充分，行文规范。不足之处有二：一是没有很好地厘...</td>\n",
       "      <td>论文选题意义突出，文章结构、论述内容严整合。不足之处主要是对家风的理论阐释有所欠缺；对家风、...</td>\n",
       "      <td>[[本论文的选题很有现实意义, 论文的结构合理、内容充实、论证逻辑性较强, 不足之处主要有：...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>本论文的选题具有较强的学术价值和现实意义，论文的结构合理、内容充实、论证逻辑性强。不足之处主...</td>\n",
       "      <td>从整体上看这是一篇校高质量的治文。只是在外文原始资料的使用以及论述中的比较分析有所不足。</td>\n",
       "      <td>论文选题有一定的前沿性，结构合理，论证充分，行文规范。不足之处：斯洛特作为当代西方有影响力的...</td>\n",
       "      <td>[[本论文的选题具有较强的学术价值和现实意义, 论文的结构合理、内容充实、论证逻辑性强, 不...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>有错别字，研究较为宽泛</td>\n",
       "      <td>国外研究不够，文献不足，创新新差，操作性不强</td>\n",
       "      <td>实证研究，体系完整，深入研究不足，针对性不足</td>\n",
       "      <td>[[有错别字, 研究较为宽泛], [国外研究不够, 文献不足, 创新新差, 操作性不强], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>有一定理论意义和现实意义，有一定创新性，摘要不完整，论述不深入，表达语言不够准确</td>\n",
       "      <td>选题偏大，国内外研究现状不足，有些观点不正确</td>\n",
       "      <td>结构清晰，格式规范，论证体系不足，缺乏创新性</td>\n",
       "      <td>[[有一定理论意义和现实意义, 有一定创新性, 摘要不完整, 论述不深入, 表达语言不够准确...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>有研究难度，具有意义，摘要不明确，研究现状不足</td>\n",
       "      <td>部分内容牵强，缺乏深入分析，比较笼统，缺少必要佐证</td>\n",
       "      <td>部分内容关联性不强，参看文献中文著作少，缺乏代表性外文。</td>\n",
       "      <td>[[有研究难度, 具有意义, 摘要不明确, 研究现状不足], [部分内容牵强, 缺乏深入分析...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Tag                                                 R1  \\\n",
       "0    1  本论文的选题很有现实意义，论文的结构合理、内容充实、论证逻辑性较强。不足之处主要有：文献综述...   \n",
       "1    1  本论文的选题具有较强的学术价值和现实意义，论文的结构合理、内容充实、论证逻辑性强。不足之处主...   \n",
       "2    1                                        有错别字，研究较为宽泛   \n",
       "3    1           有一定理论意义和现实意义，有一定创新性，摘要不完整，论述不深入，表达语言不够准确   \n",
       "4    1                            有研究难度，具有意义，摘要不明确，研究现状不足   \n",
       "\n",
       "                                                  R2  \\\n",
       "0  论文选题具有较强的现实意义，论文结构合理，论证充分，行文规范。不足之处有二：一是没有很好地厘...   \n",
       "1       从整体上看这是一篇校高质量的治文。只是在外文原始资料的使用以及论述中的比较分析有所不足。   \n",
       "2                             国外研究不够，文献不足，创新新差，操作性不强   \n",
       "3                             选题偏大，国内外研究现状不足，有些观点不正确   \n",
       "4                          部分内容牵强，缺乏深入分析，比较笼统，缺少必要佐证   \n",
       "\n",
       "                                                  R3  \\\n",
       "0  论文选题意义突出，文章结构、论述内容严整合。不足之处主要是对家风的理论阐释有所欠缺；对家风、...   \n",
       "1  论文选题有一定的前沿性，结构合理，论证充分，行文规范。不足之处：斯洛特作为当代西方有影响力的...   \n",
       "2                             实证研究，体系完整，深入研究不足，针对性不足   \n",
       "3                             结构清晰，格式规范，论证体系不足，缺乏创新性   \n",
       "4                       部分内容关联性不强，参看文献中文著作少，缺乏代表性外文。   \n",
       "\n",
       "                                               Rlist  \n",
       "0  [[本论文的选题很有现实意义, 论文的结构合理、内容充实、论证逻辑性较强, 不足之处主要有：...  \n",
       "1  [[本论文的选题具有较强的学术价值和现实意义, 论文的结构合理、内容充实、论证逻辑性强, 不...  \n",
       "2  [[有错别字, 研究较为宽泛], [国外研究不够, 文献不足, 创新新差, 操作性不强], ...  \n",
       "3  [[有一定理论意义和现实意义, 有一定创新性, 摘要不完整, 论述不深入, 表达语言不够准确...  \n",
       "4  [[有研究难度, 具有意义, 摘要不明确, 研究现状不足], [部分内容牵强, 缺乏深入分析...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c05f764-2e1f-4f60-bdf8-5aa63ac87562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict: 按专业存储经过分词的文本数据\n",
    "# key: 专业编号\n",
    "# value: 字符串列表，列表每个元素代表一个短句，每个短句形式为“word1 word2 word3”\n",
    "subject_map = {}\n",
    "total_text = []\n",
    "for name, group in grouped_reviews:\n",
    "    # 以列表形式储存字符，每个元素为一段评语\n",
    "    sent_ls = []\n",
    "    for row in group.itertuples():\n",
    "        rlist = row.Rlist\n",
    "        sent = rlist[0] + rlist[1] + rlist[2]\n",
    "        sent = [\" \".join(cut_words_with_pos(r)) for r in sent]\n",
    "        sent_ls += sent\n",
    "    subject_map[name] = sent_ls\n",
    "    total_text += (sent_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9de6bb09-0c2b-4736-ab3f-8a65e84bb9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 评价要素\n",
    "targets = [\"选题与综述：研究的理论意义，实用；对本学科及相关学科领域国内外发展状况和 学术动态的了解程度\",\n",
    "            \"创新性及论文价值：论文提出的新见解、新方法所具有的价值.论文成果对科技进步、经济建设、国家安全等方面产生的影响或作用\",\n",
    "            \"科研能力与基础知识：论文体现的理论基础的扎实程度；本学科及相关学科领域专门知识的系统性；分析问题、解决问题的能力；研究方法的科学性，是否采用先进技术、设备、信息等进行论文研究工作。\",\n",
    "            \"论文规范性:引文的规范性，学风的严谨性；论文语言表达的准确性、逻辑的严密性、书写格式及图表的规范性\" ]\n",
    "\n",
    "\n",
    "# 评价指标部分分词分词\n",
    "# map: 第i指标 -> keywords\n",
    "target_dict = {}\n",
    "for i, target in enumerate(targets):\n",
    "    words = tokenize(target, lcut)\n",
    "    word_set = []\n",
    "    # 去除重复词语\n",
    "    for word in words:\n",
    "        if word not in word_set:\n",
    "            word_set.append(word)\n",
    "    target_dict[i] = word_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1e52c2-5385-4df6-b1c2-06ac33f373a9",
   "metadata": {},
   "source": [
    "# 主题模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "311ab44c-0e26-4140-90ed-82bc177e3bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim import corpora\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.models.ldamodel import LdaModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c59af6bd-f236-46a3-9eec-f9ef96d405e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Tag = 1----------\n",
      "[(29, '0.040*\"思想\" + 0.040*\"恩格斯\" + 0.040*\"时代特征\" + 0.040*\"经济\" + 0.040*\"历史\" + 0.040*\"马克思\" + 0.040*\"地位\" + 0.040*\"循环\" + 0.040*\"论文\" + 0.040*\"方面\"'), (20, '0.139*\"马克思\" + 0.093*\"行文\" + 0.093*\"恩格斯\" + 0.047*\"循环\" + 0.047*\"经济\" + 0.047*\"价值\" + 0.047*\"表面\" + 0.047*\"思想\" + 0.047*\"理论\" + 0.047*\"分配\"'), (39, '0.288*\"理论\" + 0.146*\"理想信念\" + 0.146*\"基础\" + 0.002*\"恩格斯\" + 0.002*\"马克思\" + 0.002*\"不足\" + 0.002*\"文献\" + 0.002*\"合格\" + 0.002*\"时代背景\" + 0.002*\"直接\"'), (9, '0.098*\"教育\" + 0.049*\"论文\" + 0.049*\"现实意义\" + 0.049*\"农民\" + 0.049*\"购房\" + 0.049*\"理性\" + 0.049*\"原因\" + 0.049*\"理想信念\" + 0.049*\"个别\" + 0.049*\"区分\"')]\n",
      "---------------------------\n",
      "----------Tag = 2----------\n",
      "[(28, '0.089*\"舞弊\" + 0.067*\"分析\" + 0.045*\"实际\" + 0.023*\"案例\" + 0.023*\"方法\" + 0.023*\"研究\" + 0.023*\"动机\" + 0.023*\"监管\" + 0.023*\"机制\" + 0.023*\"手段\"'), (6, '0.104*\"关键词\" + 0.075*\"论文\" + 0.069*\"研究\" + 0.069*\"动态\" + 0.056*\"财务\" + 0.035*\"角度\" + 0.035*\"发展\" + 0.035*\"变化\" + 0.035*\"竞争力\" + 0.035*\"对象\"'), (32, '0.351*\"不足\" + 0.111*\"方面\" + 0.084*\"研究\" + 0.084*\"科学性\" + 0.028*\"论文\" + 0.028*\"工作量\" + 0.028*\"问卷\" + 0.028*\"细化\" + 0.028*\"设计\" + 0.001*\"小\"'), (12, '0.145*\"论文\" + 0.116*\"结构\" + 0.088*\"严谨\" + 0.030*\"入境游\" + 0.030*\"问题\" + 0.030*\"发展\" + 0.030*\"分析\" + 0.030*\"协同\" + 0.030*\"京津冀\" + 0.030*\"成本\"')]\n",
      "---------------------------\n",
      "----------Tag = 3----------\n",
      "[(1, '0.143*\"重点\" + 0.108*\"文章\" + 0.072*\"系统性\" + 0.072*\"空泛\" + 0.072*\"整体\" + 0.069*\"好\" + 0.036*\"偏\" + 0.036*\"新意\" + 0.036*\"国家\" + 0.036*\"法律援助\"'), (23, '0.296*\"现状\" + 0.205*\"研究\" + 0.072*\"不足\" + 0.039*\"分析\" + 0.026*\"刑法\" + 0.026*\"空洞\" + 0.013*\"原创\" + 0.013*\"版权\" + 0.013*\"互联网\" + 0.013*\"具体\"'), (8, '0.240*\"结构\" + 0.206*\"完整\" + 0.035*\"文章\" + 0.035*\"较差\" + 0.035*\"规范\" + 0.035*\"论证\" + 0.035*\"明晰\" + 0.035*\"详实\" + 0.035*\"资料\" + 0.001*\"缺憾\"'), (30, '0.070*\"概念\" + 0.056*\"法律\" + 0.036*\"一般\" + 0.036*\"阶层\" + 0.036*\"材料\" + 0.036*\"作者\" + 0.036*\"案例\" + 0.036*\"分析\" + 0.036*\"不法\" + 0.036*\"责任\"')]\n",
      "---------------------------\n",
      "----------Tag = 4----------\n",
      "[(31, '0.262*\"选题\" + 0.205*\"论文\" + 0.124*\"现实意义\" + 0.053*\"重要\" + 0.043*\"较强\" + 0.029*\"个案\" + 0.024*\"指导意义\" + 0.019*\"语法错误\" + 0.019*\"试\" + 0.010*\"示范区\"'), (34, '0.070*\"实际\" + 0.048*\"语句\" + 0.036*\"个别\" + 0.036*\"政治\" + 0.035*\"时间\" + 0.024*\"简略\" + 0.024*\"学术性\" + 0.024*\"短\" + 0.024*\"小学生\" + 0.016*\"名称\"'), (13, '0.074*\"选题\" + 0.046*\"教育\" + 0.046*\"合适\" + 0.037*\"明显\" + 0.034*\"研究\" + 0.031*\"好\" + 0.029*\"问卷\" + 0.027*\"硕士\" + 0.027*\"方式\" + 0.024*\"心理健康\"'), (3, '0.501*\"研究\" + 0.139*\"结论\" + 0.053*\"合理\" + 0.022*\"标题\" + 0.020*\"结果\" + 0.018*\"过程\" + 0.014*\"总结\" + 0.011*\"工作\" + 0.011*\"全面\" + 0.008*\"扎实\"')]\n",
      "---------------------------\n",
      "----------Tag = 5----------\n",
      "[(8, '0.101*\"新闻\" + 0.068*\"价值\" + 0.065*\"研究\" + 0.046*\"较高\" + 0.034*\"选题\" + 0.034*\"全面\" + 0.034*\"指导\" + 0.034*\"图解\" + 0.023*\"体例\" + 0.023*\"时尚\"'), (1, '0.129*\"严谨\" + 0.118*\"个别\" + 0.090*\"逻辑\" + 0.071*\"章节\" + 0.061*\"情况\" + 0.031*\"例句\" + 0.016*\"作者\" + 0.015*\"检索\" + 0.015*\"关键\" + 0.015*\"信息\"'), (33, '0.363*\"研究\" + 0.179*\"方法\" + 0.153*\"论文\" + 0.035*\"处\" + 0.020*\"相符合\" + 0.020*\"思路\" + 0.010*\"硕士学位\" + 0.010*\"优秀\" + 0.010*\"角度\" + 0.010*\"人物形象\"'), (25, '0.346*\"分析\" + 0.099*\"论文\" + 0.038*\"材料\" + 0.034*\"文本\" + 0.029*\"个案研究\" + 0.024*\"能力\" + 0.020*\"方法\" + 0.019*\"详细\" + 0.018*\"错误\" + 0.014*\"对象\"')]\n",
      "---------------------------\n",
      "----------Tag = 7----------\n",
      "[(35, '0.261*\"论文\" + 0.077*\"硕士学位\" + 0.039*\"作者\" + 0.038*\"学位\" + 0.027*\"工作\" + 0.026*\"信号\" + 0.026*\"符号\" + 0.026*\"覆盖面\" + 0.016*\"研究\" + 0.013*\"机理\"'), (36, '0.186*\"结论\" + 0.110*\"分析\" + 0.095*\"结果\" + 0.090*\"充分\" + 0.061*\"部分\" + 0.056*\"结构\" + 0.043*\"研究\" + 0.036*\"方面\" + 0.036*\"实际\" + 0.027*\"全文\"'), (39, '0.166*\"建议\" + 0.050*\"色素\" + 0.047*\"研究\" + 0.034*\"分析\" + 0.034*\"毒性\" + 0.034*\"干燥\" + 0.033*\"对策\" + 0.033*\"具体\" + 0.031*\"充分\" + 0.022*\"方法\"'), (25, '0.235*\"内容\" + 0.091*\"论文\" + 0.088*\"研究\" + 0.032*\"离心力\" + 0.022*\"工作\" + 0.021*\"球菌\" + 0.021*\"新颖\" + 0.021*\"处\" + 0.021*\"科学性\" + 0.021*\"字体\"')]\n",
      "---------------------------\n",
      "----------Tag = 8----------\n",
      "[(6, '0.146*\"错误\" + 0.105*\"题目\" + 0.096*\"论文\" + 0.083*\"单位\" + 0.074*\"个别\" + 0.059*\"时间\" + 0.059*\"语言\" + 0.049*\"现场\" + 0.038*\"标点符号\" + 0.023*\"紧密\"'), (34, '0.188*\"强\" + 0.113*\"逻辑性\" + 0.104*\"利用\" + 0.060*\"程度\" + 0.039*\"有误\" + 0.030*\"冻融\" + 0.029*\"人\" + 0.027*\"传输\" + 0.026*\"概念\" + 0.026*\"弹性\"'), (19, '0.230*\"意义\" + 0.123*\"重要\" + 0.119*\"完整\" + 0.095*\"研究\" + 0.061*\"较差\" + 0.058*\"范围\" + 0.023*\"场景\" + 0.018*\"论文\" + 0.016*\"前人\" + 0.015*\"模拟实验\"'), (12, '0.146*\"检测\" + 0.084*\"目标\" + 0.073*\"大量\" + 0.060*\"论文\" + 0.060*\"充实\" + 0.058*\"混乱\" + 0.044*\"研究\" + 0.041*\"认真\" + 0.029*\"完全\" + 0.028*\"颗粒\"')]\n",
      "---------------------------\n",
      "----------Tag = 9----------\n",
      "[(30, '0.151*\"论文\" + 0.136*\"整体\" + 0.060*\"方面\" + 0.042*\"工作量\" + 0.032*\"棉花\" + 0.032*\"综合\" + 0.032*\"一致性\" + 0.031*\"水平\" + 0.021*\"准确性\" + 0.021*\"能力\"'), (20, '0.106*\"植物\" + 0.071*\"具体\" + 0.054*\"明确\" + 0.054*\"种类\" + 0.036*\"指标\" + 0.020*\"研究\" + 0.018*\"饲料\" + 0.018*\"生产\" + 0.018*\"生化\" + 0.018*\"性能\"'), (19, '0.100*\"基因\" + 0.086*\"突变体\" + 0.043*\"最好\" + 0.043*\"叶绿体\" + 0.029*\"论文\" + 0.029*\"阿拉伯数字\" + 0.029*\"元素\" + 0.029*\"数量\" + 0.020*\"差异\" + 0.015*\"内容\"'), (5, '0.159*\"论文\" + 0.133*\"准确\" + 0.089*\"题目\" + 0.062*\"章节\" + 0.062*\"紧密\" + 0.038*\"研究\" + 0.037*\"主题\" + 0.025*\"术语\" + 0.013*\"实验\" + 0.013*\"营养\"')]\n",
      "---------------------------\n",
      "----------Tag = 10----------\n",
      "[(17, '0.261*\"建议\" + 0.218*\"设计\" + 0.110*\"合理\" + 0.070*\"错误\" + 0.019*\"特异性\" + 0.013*\"科研\" + 0.013*\"敏感性\" + 0.013*\"量\" + 0.013*\"映体\" + 0.007*\"模型\"'), (23, '0.428*\"内容\" + 0.203*\"图\" + 0.030*\"条带\" + 0.018*\"丰富\" + 0.018*\"工作\" + 0.012*\"动脉\" + 0.012*\"重新\" + 0.012*\"立论\" + 0.012*\"先进性\" + 0.008*\"图片\"'), (11, '0.107*\"值\" + 0.054*\"背景\" + 0.040*\"专业\" + 0.040*\"作者\" + 0.040*\"偏\" + 0.040*\"证\" + 0.034*\"时\" + 0.027*\"具体\" + 0.027*\"角度\" + 0.027*\"可行性\"'), (5, '0.112*\"结构\" + 0.089*\"化合物\" + 0.077*\"目标\" + 0.067*\"数据\" + 0.067*\"新意\" + 0.056*\"详尽\" + 0.034*\"条理性\" + 0.033*\"明确\" + 0.023*\"核实\" + 0.023*\"观测\"')]\n",
      "---------------------------\n",
      "----------Tag = 12----------\n",
      "[(35, '0.072*\"研究\" + 0.067*\"问题\" + 0.057*\"对象\" + 0.054*\"实际\" + 0.041*\"建议\" + 0.041*\"职能\" + 0.027*\"基层\" + 0.027*\"页码\" + 0.027*\"设置\" + 0.027*\"市级\"'), (30, '0.282*\"内容\" + 0.236*\"部分\" + 0.074*\"研究\" + 0.058*\"论文\" + 0.040*\"结论\" + 0.026*\"分析方法\" + 0.026*\"完整\" + 0.020*\"财务\" + 0.008*\"问题\" + 0.007*\"对象\"'), (7, '0.244*\"全面\" + 0.078*\"调研\" + 0.044*\"论文\" + 0.039*\"经验\" + 0.029*\"文献\" + 0.026*\"程度\" + 0.026*\"方面\" + 0.026*\"偏颇\" + 0.025*\"成功经验\" + 0.022*\"地区\"'), (3, '0.263*\"强\" + 0.106*\"文章\" + 0.089*\"数量\" + 0.036*\"人\" + 0.036*\"权威\" + 0.036*\"章节\" + 0.036*\"小结\" + 0.036*\"学术性\" + 0.018*\"能力\" + 0.018*\"报告\"')]\n",
      "---------------------------\n",
      "----------Tag = 13----------\n",
      "[(25, '0.150*\"综述\" + 0.061*\"性\" + 0.047*\"现状\" + 0.032*\"不足\" + 0.032*\"研究\" + 0.031*\"专业\" + 0.031*\"传统\" + 0.031*\"论文\" + 0.031*\"景观设计\" + 0.031*\"村落\"'), (26, '0.327*\"研究\" + 0.097*\"水平\" + 0.097*\"研究生\" + 0.065*\"方面\" + 0.062*\"文章\" + 0.048*\"充分\" + 0.032*\"绪论\" + 0.024*\"现状\" + 0.018*\"清晰\" + 0.016*\"意义\"'), (21, '0.070*\"时间\" + 0.070*\"建校\" + 0.070*\"音乐\" + 0.070*\"充分\" + 0.070*\"论据\" + 0.002*\"钟鼓楼\" + 0.002*\"游客\" + 0.002*\"街道\" + 0.002*\"餐饮\" + 0.002*\"度假区\"'), (1, '0.135*\"创作\" + 0.101*\"关联度\" + 0.068*\"预案\" + 0.068*\"过程\" + 0.068*\"大\" + 0.034*\"引子\" + 0.034*\"二者\" + 0.034*\"总结\" + 0.034*\"特色\" + 0.034*\"立体感\"')]\n",
      "---------------------------\n"
     ]
    }
   ],
   "source": [
    "# lda各专业主题\n",
    "def lda(text):\n",
    "    dictionary = corpora.Dictionary(text)  # 构建词典\n",
    "    corpus = [dictionary.doc2bow(t) for t in text]  #表示为第几个单词出现了几次\n",
    "    num_topics=4\n",
    "    ldamodel = LdaModel(corpus, num_topics=40, id2word = dictionary, passes=30,random_state = 1)   #分为4个主题\n",
    "    print(ldamodel.print_topics(num_topics=num_topics, num_words=10))  #每个主题输出10个单词\n",
    "\n",
    "    \n",
    "for key,value in subject_map.items():\n",
    "    text = [sent.split() for sent in value]\n",
    "    print(\"----------Tag = %s----------\"%key)\n",
    "    lda(text)\n",
    "    print(\"---------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce296a0-0660-4a18-85b3-1e2f13da4021",
   "metadata": {
    "tags": []
   },
   "source": [
    "# K-Means"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c797b94-a05c-4a7a-8f60-3c88270a9d99",
   "metadata": {},
   "source": [
    "## 基于word2vec的K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3d15b7db-c12c-4a1c-860c-48976b4597e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.models.word2vec import LineSentence\n",
    "from sklearn.cluster import KMeans\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e9e85d49-4a49-49cb-b660-b5a9a0f6c702",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(cut_word_list, model):\n",
    "    features = []\n",
    "    for tokens in cut_word_list:\n",
    "        zero_vector = np.zeros(model.vector_size)\n",
    "        vectors = []\n",
    "        for token in tokens:\n",
    "            if token in model.wv:\n",
    "                try:\n",
    "                    vectors.append(model.wv[token])\n",
    "                except KeyError:\n",
    "                    continue\n",
    "        if vectors:\n",
    "            vectors = np.asarray(vectors)\n",
    "            avg_vec = vectors.mean(axis=0)\n",
    "            features.append(avg_vec)\n",
    "        else:\n",
    "            features.append(zero_vector)\n",
    "    return features\n",
    "\n",
    "def KmeansByWord2vec(tag,maxN):\n",
    "    \"\"\"\n",
    "    :param tag: tag\n",
    "    :param maxN: 最大输出词数\n",
    "    :return: 各学科补充词列表\n",
    "    \"\"\"\n",
    "    docs = subject_map[tag]\n",
    "    docs = [doc.split() for doc in docs]\n",
    "    model = Word2Vec(sentences=docs, vector_size=10, workers=1, seed=SEED)\n",
    "    X = vectorize(docs, model=model)\n",
    "    keys = model.wv.key_to_index\n",
    "    kmeans = KMeans(n_clusters=4, random_state=0, n_init=\"auto\").fit(X)\n",
    "    labels = kmeans.labels_\n",
    "    centroids = kmeans.cluster_centers_\n",
    "    result_ls = [[],[],[],[]]\n",
    "    distance_ls = [[],[],[],[]]\n",
    "    for key,value in keys.items():\n",
    "        index = labels[value]\n",
    "        result_ls[index].append(key)\n",
    "        dist = np.dot((centroids[index]-value).T,(centroids[index]-value))\n",
    "        distance_ls[index].append(dist)\n",
    "    sorted_result = sorted(result_ls, key=lambda x: distance_ls[result_ls.index(x)])\n",
    "    for i in range(len(sorted_result)):\n",
    "        res = sorted_result[i]\n",
    "        if len(res) > maxN: \n",
    "            sorted_result[i] = res[:maxN]\n",
    "    return sorted_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "71d18e65-3e2a-4565-b9bd-9c08a5147f32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['论文',\n",
       "  '选题',\n",
       "  '现实意义',\n",
       "  '内容',\n",
       "  '文献',\n",
       "  '规范',\n",
       "  '论证',\n",
       "  '问题',\n",
       "  '意义',\n",
       "  '完整',\n",
       "  '充分',\n",
       "  '观点',\n",
       "  '现状',\n",
       "  '结构合理',\n",
       "  '理想信念',\n",
       "  '全面',\n",
       "  '系统',\n",
       "  '基本',\n",
       "  '思想'],\n",
       " ['研究', '理论', '价值', '强', '参考文献', '家风'],\n",
       " ['不足', '部分', '结构', '马克思', '清晰', '格式'],\n",
       " ['分析', '综述']]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 以Tag=1,maxN=20为例\n",
    "KmeansByWord2vec(1,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "64c01a3c-6d0e-4f28-8e3b-4053b6d76eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Tag = 1----------\n",
      "[['论文', '选题', '现实意义', '内容', '文献', '规范', '论证', '问题', '意义', '完整', '充分', '观点', '现状', '结构合理', '理想信念', '全面', '系统', '基本', '思想'], ['研究', '理论', '价值', '强', '参考文献', '家风'], ['不足', '部分', '结构', '马克思', '清晰', '格式'], ['分析', '综述']]\n",
      "----------Tag = 2----------\n",
      "[[], ['研究', '论文', '理论', '文献', '案例', '合理', '不足', '结构', '对策', '结论', '文章', '个别', '选题', '管理', '一般', '格式', '规范性', '评价', '简单', '清晰'], ['分析', '规范', '建议', '准确', '数据', '方面', '内容', '基础', '题目', '意义', '发展', '实际', '部分', '影响', '针对性', '语言表达', '标题', '思路', '少'], ['问题', '方法', '参考文献', '综述', '强', '图表', '薄弱', '统一']]\n",
      "----------Tag = 3----------\n",
      "[['研究', '规范', '作者'], ['不足', '问题', '强', '准确', '对策', '法治', '逻辑性', '方面'], ['论文', '部分', '内容', '文献', '个别', '观点', '陈旧', '错别字', '全面', '清晰', '明显'], ['文章', '分析', '现状', '制度', '选题', '论证', '理论', '结构', '建议', '充分', '现实意义', '合理', '创新性', '简单', '结构合理', '标题', '法律', '格式', '逻辑', '具体']]\n",
      "----------Tag = 4----------\n",
      "[['研究', '不足', '调查', '理论', '问卷', '文献', '价值', '教育', '规范', '逻辑', '明确', '院校', '重要', '水平', '清楚', '大', '参考文献', '新', '作者', '详细'], ['论文', '方法', '学生', '结果', '意义', '概念', '过程', '清晰', '合理', '主题', '行文', '幼儿园', '具体', '结构', '基本', '格式', '小学生', '工具', '情况', '方式'], ['问题', '选题', '教学', '内容', '结论', '数据', '建议', '管理', '对象', '能力', '模式', '运用', '界定', '文章', '整体', '教师', '对策', '针对性', '高职', '资料'], ['分析', '部分', '设计', '现状', '课程', '现实意义', '关系', '评价', '实验', '综述', '小学', '方面', '原因', '策略', '视角', '培训', '少', '基础', '论证', '影响']]\n",
      "----------Tag = 5----------\n",
      "[['论文', '价值', '结构', '学术', '方面', '文章', '行文', '错误', '意义', '语言表达', '影响', '创新性', '大', '总结', '跨文化', '正文', '任务', '语法错误', '汉语', '处'], ['研究', '部分', '文献', '准确', '结论', '充分', '传播', '论证', '文本', '特点', '文化', '对象', '具体', '现象', '关系', '明确', '合理', '女性', '材料', '句子'], ['分析', '规范', '理论', '语言', '章节', '逻辑', '清晰', '严谨', '质量', '角度', '观点', '词典', '水平', '口译', '原文', '风格', '个案研究', '意识', '建设', '奏议'], ['问题', '选题', '内容', '方法', '报告', '不足', '译文', '案例', '参考文献', '标题', '作者', '过程', '建议', '个别', '明显', '主题', '格式', '策略', '整体', '综述']]\n",
      "----------Tag = 7----------\n",
      "[['论文', '规范', '分析', '部分', '格式', '问题', '结果', '影响', '书写', '实验', '结构', '语言', '意义', '优化', '条件', '准确', '活性', '严谨', '大', '能力'], ['研究', '方法', '内容', '参考文献', '综述', '个别', '工作', '创新性', '图', '工作量', '新', '理论', '试验', '充分', '价值', '催化剂', '材料', '标题', '英文', '方面'], ['文献', '选题', '金属', '直接', '合理', '碳', '强', '普尔'], ['结论', '不足', '统一', '数据', '过程', '设计', '详细', '动态', '色素', '领域', '简洁', '好']]\n",
      "----------Tag = 8----------\n",
      "[['论文', '图', '结论', '建议', '不足', '影响', '设计', '格式', '结构', '少', '性能', '文字', '不同', '总结', '工艺', '题目', '充分', '因素', '工作量', '准确'], ['研究', '分析', '内容', '规范', '实验', '参考文献', '结果', '选题', '算法', '清晰', '综述', '错误', '合理', '方面', '基本', '正文', '方案', '科学', '能力', '情况'], ['方法', '部分', '问题', '文献', '数据', '模型', '实际', '技术', '意义', '工程', '英文', '价值', '参数', '统一', '大', '研究成果', '简单', '全面', '标题', '公式'], ['理论', '系统', '试验', '作者', '现状', '创新性', '工作', '过程', '明确', '基础', '数值', '具体', '图表', '强', '评价', '检测', '重要', '动态', '详细', '效果']]\n",
      "----------Tag = 9----------\n",
      "[['论文', '研究', '规范', '文献', '内容', '格式', '结论', '试验', '方法', '综述', '设计', '建议', '结果', '不同', '选题', '明确', '准确', '标题', '影响', '理论'], ['部分', '玉米', '大', '实际', '强', '项目', '实验', '金莲花', '语言表达', '关联性'], ['参考文献', '分析', '题目', '少', '评价', '数据', '语句', '统一', '陈旧', '研究进展', '对象', '清楚', '工作量', '综合'], ['问题', '不足', '图', '文章', '科学', '土壤', '方面', '具体', '植物', '简单', '基因', '充分', '品种', '显著性', '材料', '指标', '学名', '专业', '硕士学位', '作者']]\n",
      "----------Tag = 10----------\n",
      "[['研究', '规范', '结果', '内容', '方法', '格式', '实验', '指标', '图', '创新性', '准确', '少', '病例', '英文', '严谨', '数据', '患者', '时间', '对照组', '逻辑'], ['论文', '不足', '参考文献', '分析', '设计', '临床', '明确', '陈旧', '简单', '例数', '影响', '图表', '新颖', '水平', '资料', '高', '错误', '具体', '材料', '统一'], ['部分', '书写', '题目', '综述', '选题', '问题', '文字', '样本量', '合理', '个别', '价值', '分组', '图片', '新颖性', '充分', '语言表达', '检验', '质量', '处', '中文'], ['结论', '建议', '文献', '标准', '统计学', '清晰', '课题', '检测', '语言', '细胞', '明显', '目的', '强', '严密', '差异', '方案', '表格', '结构', '规范性', '基因']]\n",
      "----------Tag = 12----------\n",
      "[['论文', '不足', '简单', '综述', '建议', '评价', '合理', '调查', '全面', '设计', '案例', '战略', '模式', '准确', '现状', '运用', '公司', '语言表达', '意义', '模型'], ['研究', '分析', '参考文献', '内容', '数据', '管理', '具体', '充分', '方面', '实际', '好', '问卷', '综合', '工具', '清晰', '整体', '逻辑性', '行文', '专业', '作者'], ['问题', '文献', '理论', '方法', '选题', '少', '题目', '结论', '陈旧', '明确', '发展', '针对性', '标题', '优化', '建设', '影响', '体系', '指标体系', '总结', '系统'], ['规范', '部分', '对策', '结构', '对象', '基础', '强', '格式', '原因', '能力', '序号', '政策', '青少年', '创新性', '思路', '旅游', '分析方法', '新', '动态', '市场']]\n",
      "----------Tag = 13----------\n",
      "[['论文', '文章', '专业', '创新性', '作者', '方法', '逻辑', '新意', '理念'], ['研究', '不足', '选题', '部分', '理论', '内容', '参考文献', '作品', '基本', '分析', '整体', '音乐', '动态', '充分', '观点', '景观设计', '规范', '综述', '简单', '题目'], ['设计', '水平', '文献', '主题', '价值', '章节', '问题', '领域', '意义', '特色'], ['创作']]\n"
     ]
    }
   ],
   "source": [
    "write = pd.ExcelWriter(\"/Users/antonchekhov/Desktop/Keywords.xlsx\")\n",
    "maxN = 20\n",
    "for key in subject_map.keys():\n",
    "    print(\"----------Tag = %s----------\"%key)\n",
    "    KWs = KmeansByWord2vec(key,maxN)\n",
    "    # KWs = pd.DataFrame(KWs)\n",
    "    print(KWs)\n",
    "    # KWs.to_excel(write,'KM%s'% key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e2147d-7f2f-43b3-aaae-386012615f23",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 情感计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7640d602-fdd4-43be-91bb-9cb537f5f5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snownlp import SnowNLP\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1dbc63e2-cacd-4268-8269-53e11169da18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentence:  选题具有理论意义和现实意义，论文语言流畅，总体架构基本合理\n",
      "The sentiment score of the sentence:  0.999844598829318\n",
      "\n",
      "\n",
      "The sentence:  论文写作粗糙，表格图表不严谨。\n",
      "The sentiment score of the sentence:  0.28852731551433597\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s1 = '选题具有理论意义和现实意义，论文语言流畅，总体架构基本合理'\n",
    "s2 = '论文写作粗糙，表格图表不严谨。'\n",
    "\n",
    "for s in [s1,s2]:\n",
    "    print('The sentence: ',s)\n",
    "    print('The sentiment score of the sentence: ', SnowNLP(s).sentiments)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "212a687a-24a4-49b0-8bc8-b7dc3007e49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentimentsCal(text, target_dict):\n",
    "    \"\"\"\n",
    "    计算短句的情感值\n",
    "    :param text: 短句文本\n",
    "    :param target_dict: 指标词典\n",
    "    :return: 情感值列表[,,]\n",
    "    \"\"\"\n",
    "    scores = [0,0,0,0]\n",
    "    count = [0,0,0,0]\n",
    "    sentiment = SnowNLP(text).sentiments\n",
    "    words = tokenize(text, lcut)\n",
    "    '''\n",
    "    for key, value in enumerate(target_dict):\n",
    "        count[key] = len(value)\n",
    "        for kw in value:\n",
    "            if kw in words:\n",
    "                scores[key] += 25\n",
    "            else:\n",
    "                scores[key] += 22.5\n",
    "    scores = [ scores[i]/count[i]*sentiment for i in range(4) ]\n",
    "    '''\n",
    "    for key,value in enumerate(target_dict):\n",
    "        for kw in value:\n",
    "            if kw in words:\n",
    "                scores[key] += sentiment\n",
    "                count[key] += 1\n",
    "    for i,cnt in enumerate(count):\n",
    "        if cnt == 0:\n",
    "            scores[i] = 1\n",
    "        else:\n",
    "            scores[i] = scores[i] / count[i]\n",
    "\n",
    "    return scores\n",
    "\n",
    "def ReviewSentiments(reviews,target_dict):\n",
    "    \"\"\"\n",
    "    计算句子列表的情感值\n",
    "    :param reviews: 短句列表\n",
    "    :return: 情感值列表np.array([,,])\n",
    "    \"\"\"\n",
    "    num = len(reviews)\n",
    "    if num == 0:\n",
    "        return 0\n",
    "    scores = [ sentimentsCal(review,target_dict) for review in reviews]\n",
    "    scores = np.array(scores)\n",
    "    mean =np.sum(scores,axis=0)/num\n",
    "    return mean\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e0a48a61-2b02-415b-b239-c4cfaf638350",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"mergeDict.xlsx\"\n",
    "cols = [\"选题与综述\",\"创新与论文价值\",\"科研能力与基础知识\",\"论文规范性\"]\n",
    "new_reviews_df = reviews_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cf9a885f-ec7a-41bc-bf19-deb34e330170",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = [[],[],[]]\n",
    "\n",
    "for row in reviews_df.itertuples():\n",
    "    review_ls = row.Rlist\n",
    "    tag = row.Tag\n",
    "    keyword_df = pd.read_excel(path,str(tag))\n",
    "    keyword_dict = [list(keyword_df[col]) for col in cols]\n",
    "    for i,reviews in enumerate(review_ls):\n",
    "        score = ReviewSentiments(reviews, keyword_dict)\n",
    "        scores[i].append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "45dfe549-fe99-455a-8d9e-db499ee19cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,4):\n",
    "    score_ls = scores[i-1]\n",
    "    for j in range(1,5):\n",
    "        sls = []\n",
    "        for score in score_ls:\n",
    "            if type(score) == int:\n",
    "                sls.append(-1)\n",
    "            else:\n",
    "                sls.append(score[j-1])\n",
    "        new_reviews_df[\"S%s%s\"%(i,j)] = pd.Series(sls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d186823c-2bba-494e-a4be-4bbd3ce656ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_reviews_df.head(10)\n",
    "# new_reviews_df.to_excel(\"result.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
